{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook we are going to create a simple agentic system that will generate ideas given a topic. The system is made up of two agents, named \"Idea maker\" and \"Idea Hater\". These agents will create and critizice ideas, and will interact with each other to refine and improve the idea.\n",
        "\n",
        "The slides associated to this notebook can be found [here](https://docs.google.com/presentation/d/1iuve05pqrZtt4RxbViAl4l8lvLwh3cUKWzT5wrqk6Bg/edit?usp=sharing).\n",
        "\n",
        "These agents represent a simplified version of the Idea module in [Denario](https://arxiv.org/abs/2510.26887). See [this link](https://astropilot-ai.github.io/DenarioPaperPage/) for more details.  "
      ],
      "metadata": {
        "id": "m4txWMbN3Zch"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "PB6qEYed5lF4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets install the relevant packages to create the agentic system:"
      ],
      "metadata": {
        "id": "VA6PcOYx5oRt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langgraph -q\n",
        "!pip install langchain -q\n",
        "!pip install langchain-google-genai -q"
      ],
      "metadata": {
        "collapsed": true,
        "id": "yDbDWUmY-xJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this tutorial we will be using Gemini models. To use them, we need an API key. Lets set the GOOGLE API Key\n",
        "\n",
        "Go to [this link](https://ai.google.dev/gemini-api/docs/api-key) to get your key if you don't have one already."
      ],
      "metadata": {
        "id": "gelnvIJ7hIGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "GOOGLE_API_KEY = getpass.getpass('Enter your Gemini API key: ')"
      ],
      "metadata": {
        "id": "h4ivFXE3--cX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before diving into the system, lets see how to call Large Language Models (LLMs) and manipulate their output. For this, lets use Gemini"
      ],
      "metadata": {
        "id": "Pjb03CZi7HhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model='gemini-2.0-flash', temperature=0.5, google_api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "DKXLEeRACeRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets define the message we will be passing to the LLM. In LangChain/LangGraph, there are three kind of messages:\n",
        "- HumanMessage: These are messages the user/human will send to the LLM\n",
        "- AIMessage: These are messages coming from LLM. Typically, the output to a query.\n",
        "- SystemMessage: These are messages send to the LLM to define its behaviour. For instance: \"You are an astrophysicist\". Note that these messages may not be supported by all LLMs."
      ],
      "metadata": {
        "id": "VjXTHhQi_lBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "message = [HumanMessage(content=\"Tell me something about NASA\")]"
      ],
      "metadata": {
        "id": "RAHTvRCDEqXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have defined the LLM and the prompt, we can invoke it:"
      ],
      "metadata": {
        "id": "qvD481zhAFGO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = llm.invoke(message)"
      ],
      "metadata": {
        "id": "cC5HeeI_Foau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Differently to the straight output we get when using ChatGPT or Gemini in a browser, with LangChain/LangGraph, we get an output with lots of details"
      ],
      "metadata": {
        "id": "I5WL29mPAK0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "id": "8oG6NUFYFrzO",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To print just the output content do:"
      ],
      "metadata": {
        "id": "2by7dvLPjcdF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(result.content)"
      ],
      "metadata": {
        "id": "xCk42SuZf_Bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are many different fields that are actually very important when designing agentic systems"
      ],
      "metadata": {
        "id": "Fk4ImRHvjijp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result.usage_metadata['output_tokens']"
      ],
      "metadata": {
        "id": "a69Mhkn0HJiM",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, lets move on and start building our agentic system.\n",
        "\n",
        "Lets define the graph state. This is a python dictionary that contains information that all agents can access, edit, and add. It is critical to establish the communication between agents, and the context/memory of them."
      ],
      "metadata": {
        "id": "kfNZDIqHjTjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import TypedDict, Any\n",
        "from typing import Annotated, Literal\n",
        "from langchain_core.messages import AnyMessage\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "class GraphState(TypedDict):\n",
        "  topic: str\n",
        "  idea: str\n",
        "  previous_ideas: str\n",
        "  previous_critiques: str\n",
        "  iteration: int"
      ],
      "metadata": {
        "id": "im7HDnuAH7M6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets create the agents for our system. In this case, we only have 2:\n",
        "- Idea maker: this agent is in charge of generating an idea given a topic and any available feedback\n",
        "- Idea maker: this agent is in charge or criticizing an idea"
      ],
      "metadata": {
        "id": "nUlL6NIf3y1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def idea_maker(state: GraphState):\n",
        "\n",
        "  PROMPT = [HumanMessage(content=f\"\"\"Given the topic below generate an interesting idea for a science project. Take into account any critique provided and previous generated ideas, if any:\n",
        "\n",
        "  Topic:\n",
        "  {state['topic']}\n",
        "\n",
        "  Previous ideas:\n",
        "  {state['previous_ideas']}\n",
        "\n",
        "  Previous critiques:\n",
        "  {state['previous_critiques']}\n",
        "  \"\"\")]\n",
        "\n",
        "  llm = ChatGoogleGenerativeAI(model='gemini-2.0-flash', temperature=0.7, google_api_key=GOOGLE_API_KEY)\n",
        "\n",
        "  result = llm.invoke(PROMPT)\n",
        "  idea = result.content  #just get the content, not all the other information\n",
        "  state['iteration'] += 1 #increase the counter by one\n",
        "\n",
        "  display(HTML(\"<p style='color:Green'>########### Idea ###########</p>\"))\n",
        "  print(idea)\n",
        "  display(HTML(\"<p style='color:Green'>############################</p>\"))\n",
        "\n",
        "  previous_ideas = f\"\"\"\n",
        "  {state['previous_ideas']}\n",
        "\n",
        "  Iteration {state['iteration']}:\n",
        "  {idea}\n",
        "  \"\"\"\n",
        "\n",
        "  return {'idea': idea, 'iteration':state['iteration'], 'previous_ideas':previous_ideas}"
      ],
      "metadata": {
        "id": "1mXE6gZcOkdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets create the idea hater agent"
      ],
      "metadata": {
        "id": "oVZXaIhW45on"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def idea_hater(state: GraphState):\n",
        "\n",
        "  PROMPT = [HumanMessage(content=f\"\"\"Critique the proposed idea in order to improve it. Take into account all previous ideas, and critiques, if any,:\n",
        "\n",
        "  Topic:\n",
        "  {state['topic']}\n",
        "\n",
        "  Current idea:\n",
        "  {state['idea']}\n",
        "\n",
        "  Previous ideas:\n",
        "  {state['previous_ideas']}\n",
        "\n",
        "  Critiques:\n",
        "  {state['previous_critiques']}\n",
        "  \"\"\")]\n",
        "\n",
        "  llm = ChatGoogleGenerativeAI(model='gemini-2.5-flash', temperature=0.8, google_api_key=GOOGLE_API_KEY)\n",
        "\n",
        "  result = llm.invoke(PROMPT)\n",
        "  critique = result.content\n",
        "\n",
        "  previous_critiques = f\"\"\"\n",
        "  {state['previous_critiques']}\n",
        "\n",
        "  Iteration {state['iteration']}:\n",
        "  {critique}\n",
        "  \"\"\"\n",
        "\n",
        "  display(HTML(\"<p style='color:red'>########### Critique ###########</p>\"))\n",
        "  print(critique)\n",
        "  display(HTML(\"<p style='color:red'>################################</p>\"))\n",
        "\n",
        "  return {'previous_critiques':previous_critiques}"
      ],
      "metadata": {
        "id": "lgDYbq6XZBLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to create this simple python function to define the which node/agent should go after idea maker. In this case, if less than three iterations, the idea generated by idea maker is send to idea hater. After 3 iterations, the system ends."
      ],
      "metadata": {
        "id": "VNQ-j55t4_Nu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Idea maker - hater router\n",
        "def router(state: GraphState) -> Literal['hater', '__end__']:\n",
        "\n",
        "    if state['iteration']<3:\n",
        "        return \"hater\"\n",
        "    else:\n",
        "        return \"__end__\"\n"
      ],
      "metadata": {
        "id": "ekzd9A35QyTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now define the computational graph. This defines the agentic workflow, i.e. how agents interact with each other and how the system progresses."
      ],
      "metadata": {
        "id": "pB8OMcHx6L8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import START, StateGraph, END\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from IPython.display import Image, display, HTML\n",
        "\n",
        "# Define the graph\n",
        "builder = StateGraph(GraphState)\n",
        "\n",
        "# Define nodes: these do the work\n",
        "builder.add_node(\"maker\",             idea_maker)\n",
        "builder.add_node(\"hater\",             idea_hater)\n",
        "\n",
        "# Define edges: these determine how the control flow moves\n",
        "builder.add_edge(START,                 \"maker\")\n",
        "builder.add_conditional_edges(\"maker\",  router)\n",
        "builder.add_edge(\"hater\",               \"maker\")\n",
        "\n",
        "\n",
        "memory = MemorySaver()\n",
        "graph  = builder.compile(checkpointer=memory)\n",
        "\n",
        "# # generate an scheme with the graph\n",
        "try:\n",
        "    import requests\n",
        "    original_post = requests.post\n",
        "\n",
        "    def patched_post(*args, **kwargs):\n",
        "        kwargs.setdefault(\"timeout\", 30)  # Increase timeout to 30 seconds\n",
        "        return original_post(*args, **kwargs)\n",
        "\n",
        "    requests.post = patched_post\n",
        "    graph_image = graph.get_graph(xray=True).draw_mermaid_png()\n",
        "    display(Image(data=graph_image))\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ Failed to generate or save graph diagram: {e}\")"
      ],
      "metadata": {
        "id": "_Kh6nyitRqwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we that we have 1) the agents, 2) the graph state, and 3) the computational graph we can run the system."
      ],
      "metadata": {
        "id": "2splyOpZ6fA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = {'topic':'scaling relations of galaxy clusters',\n",
        "         'previous_ideas': '',\n",
        "         'idea': '',\n",
        "         'previous_critiques': '',\n",
        "         'iteration': 0}\n",
        "result = graph.invoke(input, config={\"configurable\": {\"thread_id\": \"run-001\"}})\n"
      ],
      "metadata": {
        "id": "36ZxLxiHR-eA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise:** Modify the above system to include a final agent that will summarize the conversation between the maker and hater agents"
      ],
      "metadata": {
        "id": "g0wFCRDGh-v8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s7d-9GvkXGjn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}